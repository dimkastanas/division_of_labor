// webppl RR_simulations.wppl --require ./refModule
var context = {
    target: ["two small green square"],
    neutral: ["two small green circle", "one small green star"],
    competitor: ["two small green circle", "one small blue square"],
    alternative: ["two small green circle", "one small green pentagon"]
}

// property categories
var categories = {
  shapes: ["circle", "square", "triangle", "pentagon", "star"],
  colours: ["green", "pink", "black", "blue"],
  sizes: ["small", "big"],
  numbers: ["two", "one"]
};

// subset of possible utterances
var possibleUtterances = Categorical({
  vs: [
    // references to the target
    "green",
    "square",
    "small",
    "two small green square",
    "small green square",
    "green square",
    "small square",
    "small green",
    "two small",
    "two green",
    "two square",

    // references to the competitor, alternative and neutral
    "circle",
    "star",
    "two small green circle",
    "blue square",
    "two small blue square",
    "pentagon",
    "two small green pentagon",

    // references using only
    "small only",
    "green only",
    "square only",
    "circle only",
    "two small green square only",
  ],
});

var possibleScenes = Categorical({vs: [context['target'].concat(["two small blue square"])]});

// these are the possible mixture weights for perspective-taking
// where 0 is purely egocentric and 1 is purely partner's perspective
var possibleWeightings = Categorical({
  vs: _.range(0, 1, 0.1),
});

// alpha: soft-max temperature
// <feature>Cost: cost associated with producing this feature
// perspectiveCost: cost associated with perspective-taking
var params = {
  alpha: 5,
  costWeight: 0.2,
  perspectiveCost: 0,
};

var meaning = function (utt, scene) {
  var descriptors = utt.split(" ");
  
  // without "only", we check whether any element matches all the descriptors
  if (!_.includes(descriptors, "only")) {
    return any(function(obj) {
      return all(function(descriptor) {
        return _.includes(obj.split(" "), descriptor);
      }, descriptors);
    }, scene);
  } 
  
  return all(function(descriptor) {
    // otherwise, with "only", we check whether for every category of descriptors, 
    // there is no other object that has a different value for that category
    var category = find(function(key) {
      return _.includes(categories[key], descriptor);
    }, _.keys(categories));
    
    // Get unique values from this category 
    var uniqueValues = reduce(function(obj, values) {
      var value = _.intersection(obj.split(" "), categories[category])[0];
      return _.includes(values, value) ? values : values.concat(value);
    }, [], scene);
    
    // For 'only', check if there is exactly one value in the category
    return uniqueValues.length === 1 && uniqueValues[0] === descriptor;
  }, _.without(descriptors, "only"));
};

// var getTrueUtterances = function(context) {
//   // Get all scenes from the context (excluding private)
//   var visibleScenes = _.values(context);

//   // Filter utterances that are true for at least one object
//   var trueUtts = filter(function(utt) {
//     return any(function(obj) {
//       console.log(obj)
//       return meaning(utt, obj);
//     }, visibleScenes);
//   }, possibleUtterances.support());
//   return Categorical({ vs: trueUtts });
// };

var uttCost = function (utt) {
  return params.costWeight * utt.split(" ").length;
};

// derives the speaker's perspective from the listener's visible context
var getSpeakerView = function (listenerContext) {
  return _.omit(listenerContext, 'private');
};

// L0 interprets utterance literally using fixed mixture of perspectives
var L0 = cache(function (utt, context, weighting) {
  return Infer({ method: "enumerate" }, function () {
    var partnerContext = flip(weighting) ? getSpeakerView(context) : context;
    var scene = uniformDraw(_.values(partnerContext));
    factor(meaning(utt, scene) ? Math.log(1) : Math.log(0.01));
    return scene;
  });
});

// S1 selects utterance using fixed mixture of perspectives
// (given belief about L0's mixture)
var S1 = cache(function (target, context, ownWeighting) {
  return Infer({ method: "enumerate" }, function () {
    var utt = sample(possibleUtterances);
    var egocentricUtility = L0(utt, context, 0).score(target) 
    var combinedUtility = expectation(possibleWeightings, function (partnerWeighting) {
      var asymmetricUtility = expectation(possibleScenes, function (scene) {
        var possibleListenerView = extend(context, {'private' : scene});
        return (L0(utt, possibleListenerView, partnerWeighting).score(target));
      });
      return (ownWeighting * asymmetricUtility +
              (1 - ownWeighting) * egocentricUtility);
    });
    factor(params.alpha * (combinedUtility - uttCost(utt, params)));
    return utt;
  });
});

// L1 selects scenes given belief about S1's mixture
var L1 = function (utt, context, ownWeighting) {
  return Infer({ method: "enumerate" }, function () {
    var perspective = flip(ownWeighting) ? "other" : "own";
    var partnerContext =
      perspective == "own" ? context : getSpeakerView(context);
    var partnerWeight = perspective == "own" ? 0 : sample(possibleWeightings);

    var object = uniformDraw(partnerContext);
    observe(S1(object, partnerContext, partnerWeight), utt);
    return object;
  });
};

// meta-cognitive resource-rational speaker selects optimal mixture
// weight, marginalizing over uncertainty about listener's weight
var RR_speaker = function (target, context) {
  return Infer({ method: "enumerate" }, function () {
    var ownWeighting = sample(possibleWeightings);

    // Imagine how speaker with this weight would behave
    var likelyUtt = MAP(S1(target, context, ownWeighting))["val"];
    // Imagine expected utility of that behavior, marginalizing over
    // partner's mixture weight and possible objects in partner's view
    var utility = expectation(possibleScenes, function (obj) {
      return expectation(possibleWeightings, function (partnerWeighting) {
        var possibleListenerView = context.concat(obj + " private");
        return L0(likelyUtt, possibleListenerView, partnerWeighting).score(
          target
        );
      });
    });
    // putting more weight on partner's perspective is costly
    factor(utility - ownWeighting * params.perspectiveCost);
    return {
      weighting: ownWeighting,
      perspectiveCost: params.perspectiveCost,
      alpha: params.alpha,
      //uttCost: argv.uttCost,
    };
  });
};

// meta-cognitive resource-rational speaker selects optimal mixture
// weight, marginalizing over uncertainty about listener's weight
var RR_listener = function (utt, baseContext) {
  return Infer({ method: "enumerate" }, function () {
    var ownWeighting = sample(possibleWeightings);

    // Marginalize over partner's mixture weight and possible hidden objects
    var utility = expectation(possibleScenes, function (hiddenObj) {
      return expectation(possibleWeightings, function (partnerWeighting) {
        var context = baseContext.concat(hiddenObj + " private");
        var realSpeakerView = getSpeakerView(context);
        var worstCaseTarget = last(realSpeakerView);
        var likelyUtt = MAP(
          S1(worstCaseTarget, realSpeakerView, partnerWeighting)
        )["val"];
        return L1(likelyUtt, context, ownWeighting).score(worstCaseTarget);
      });
    });

    // putting more weight on partner's perspective is costly
    factor(utility - ownWeighting * params.perspectiveCost);
    return {
      weighting: ownWeighting,
      perspectiveCost: params.perspectiveCost,
      alpha: params.alpha,
    };
  });
};

// Helper function to run a test and show pass/fail status
var runTest = function(name, utterance, scene, expected) {
  var result = meaning(utterance, scene);
  var passed = result === expected;
  var status = passed ? "✓ PASS" : "✗ FAIL";
  console.log(name + ": " + status + " (got " + result + ", expected " + expected + ")");
};

// Basic property tests
console.log("\nBasic property tests:");
runTest("1. Basic circle match", "circle", ["two small green circle"], true);
runTest("2. No circle match", "circle", ["two small green square"], false);
runTest("3. Color match", "green", ["two small green circle"], true);
runTest("4. Multiple properties", "small green", ["two small green square"], true);

// Multiple objects in scene
console.log("\nMultiple objects tests:");
runTest("5. Green in all objects", "green", ["two small green circle", "one small green star"], true);
runTest("6. No blue objects", "blue", ["two small green circle", "one small green star"], false);
runTest("7. Small in all objects", "small", ["two small green circle", "one small green star"], true);

// 'only' tests
console.log("\n'only' tests:");
runTest("8. Only circles (single object)", "circle only", ["two small green circle"], true);
runTest("9. Only circles (multiple objects)", "circle only", ["two small green circle", "one small green star"], false);
runTest("10. Only green", "green only", ["two small green circle", "one small green star"], true);
runTest("11. Only small", "small only", ["two small green circle", "one small green star"], true);
runTest("12. Only star", "star only", ["two small green circle", "one small green star"], false);

// Multiple descriptors with 'only'
console.log("\nMultiple descriptors with 'only':");
runTest("17. Only small and green", "small green only", ["two small green circle", "one small green star"], true);
runTest("18. Only small and green (different colors)", "small green only", ["two small green circle", "one small blue star"], false);
runTest("19. Only small and green (different sizes)", "small green only", ["two small green circle", "one big green star"], false);

// Helper function to run L0 tests
var runL0Test = function(name, utterance, context, weighting, expectedTarget, expectedProbability) {
  var result = L0(utterance, context, weighting);
  var targetProbability = Math.exp(result.score(expectedTarget));
  var passed = Math.abs(targetProbability - expectedProbability) < 0.01;
  var status = passed ? "✓ PASS" : "✗ FAIL";
  console.log(name + ": " + status + 
    " (got " + targetProbability.toFixed(3) + 
    ", expected " + expectedProbability.toFixed(3) + ")");
};

// L0 Tests
console.log("\nL0 Tests:");
console.log(context);

runL0Test("1. Basic egocentric interpretation", "green", context, 0, context.target, 0.2);
runL0Test("2. Basic partner perspective interpretation", "green", context, 1, context.target, 0.25);
runL0Test("3. Mixed perspective interpretation", "green", context, 0.5, context.target, 0.225);
runL0Test("4. Specific utterance with multiple properties", "two small green square", context, 0, context.target, 0.333);
runL0Test("5. 'only' utterance interpretation", "square only", context, 0, context.target, 0.96);
runL0Test("6. Non-matching utterance", "blue", context, 0, context.target, 0.0);

// Helper function to run S1 tests
var runS1Test = function(name, target, context, weighting, expectedUtterance, expectedProbability) {
  var result = S1(target, context, weighting);
  var utteranceProbability = Math.exp(result.score(expectedUtterance));
  var passed = Math.abs(utteranceProbability - expectedProbability) < 0.01;
  var status = passed ? "✓ PASS" : "✗ FAIL";
  console.log(name + ": " + status + 
    " (got " + utteranceProbability.toFixed(3) + 
    ", expected " + expectedProbability.toFixed(3) + ")");
};

// S1 Tests
console.log("\nS1 Tests:");

runS1Test("1. Basic egocentric speaker", context.target, context, 0, "green square", 0.27);
runS1Test("2. Basic partner perspective speaker", context.target, context, 1, "green square", 0.238);
runS1Test("3. Mixed perspective speaker", context.target, context, 0.5, "green square", 0.259);

console.log(JSON.stringify(S1(["two small green square"], context, 0)))
console.log(JSON.stringify(S1(["two small green square"], context, 1)))