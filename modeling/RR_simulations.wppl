// webppl RR_simulations.wppl --require ./refModule

var contexts = json.read('input/all_world_states.json')
var possibleObjects = Categorical({vs: map(function(v) {return v['target']}, contexts)})
var possibleUtterances = Categorical({vs: json.read('input/possibleExpressionsWithOnly.json')});

// these are the possible mixture weights for perspective-taking
// where 0 is purely egocentric and 1 is purely partner's perspective
var possibleWeightings = Categorical({
  vs: _.range(0, 1, 0.1)
});


// alpha: soft-max temperature
// <feature>Cost: cost associated with producing this feature
// perspectiveCost: cost associated with perspective-taking
var params = {
  alpha: 3,
  costWeight: .02,
  perspectiveCost : 0
};

// utterance is true if object has all of the mentioned features
var meaning = function(utt, object) {
  var descriptors = utt.split(' ');
  var objProperties = object.split(' ')
  var matches = _.every(map(function(descriptor) {
    return _.includes(objProperties, descriptor);
  }, descriptors));
  return matches;
};

var getTrueUtterances = function(context) {
  var trueUtts = filter(function(utt) {
    return _.some(map(function(obj) {
      return meaning(utt, obj);
    }, context));
  }, possibleUtterances.support());
  return Categorical({vs: trueUtts});
};

// cost of producing utterance is sum of costs of the component words
var uttCost = function(utt) {
  return params.costWeight * utt.split(' ').length
};

// derives the speaker's perspective from the listener's visible context
var getSpeakerView = function(listenerContext) {
  var hiddenObj = find(function(x) {return last(x.split(' ')) == 'private';}, listenerContext);
  return remove(hiddenObj, listenerContext);
};

// L0 interprets utterance literally using fixed mixture of perspectives
var L0 = cache(function(utt, context, weighting) {
  return Infer({method: 'enumerate'}, function() {
    var perspective = flip(weighting) ? 'other' : 'own';
    var partnerContext = perspective == 'own' ? context : getSpeakerView(context);
      var object = uniformDraw(partnerContext);
    factor(meaning(utt, object) ? Math.log(1) : Math.log(0.01));
    return object;
  });
});

// S1 selects utterance using fixed mixture of perspectives
// (given belief about L0's mixture)
var S1 = cache(function(target, context, ownWeighting) {
  return Infer({method: 'enumerate'}, function() {
    var utt = sample(getTrueUtterances(context));
    var egocentricUtility = L0(utt, context, 0).score(target) - uttCost(utt,params);
    var combinedUtility = expectation(possibleWeightings, function(partnerWeighting) {
      var asymmetricUtility = expectation(possibleObjects, function(obj) {
        var possibleListenerView = context.concat(obj + ' private');
        return L0(utt, possibleListenerView, partnerWeighting).score(target) - uttCost(utt,params);
      });
      return ownWeighting * asymmetricUtility + (1 - ownWeighting) * egocentricUtility;
    });
    factor(params.alpha * combinedUtility);
    return utt;
  });
});

// L1 selects objects given belief about S1's mixture
var L1 = function(utt, context, ownWeighting) {
  return Infer({method: 'enumerate'}, function() {
    var perspective = flip(ownWeighting) ? 'other' : 'own';
    var partnerContext = perspective == 'own' ? context : getSpeakerView(context);
    var partnerWeight = perspective == 'own' ? 0 : sample(possibleWeightings);

    var object = uniformDraw(partnerContext);
    observe(S1(object, partnerContext, partnerWeight), utt);
    return object;
  });
};

// meta-cognitive resource-rational speaker selects optimal mixture
// weight, marginalizing over uncertainty about listener's weight
var RR_speaker = function(target, context) {
  return Infer({method: 'enumerate'}, function() {
    var ownWeighting = sample(possibleWeightings);

    // Imagine how speaker with this weight would behave
    var likelyUtt = MAP(S1(target, context, ownWeighting))['val'];
      console.log(likelyUtt)
    // Imagine expected utility of that behavior, marginalizing over
    // partner's mixture weight and possible objects in partner's view
    var utility = expectation(possibleObjects, function(obj) {
      return expectation(possibleWeightings, function(partnerWeighting) {
        var possibleListenerView = context.concat(obj + ' private');
        return L0(likelyUtt, possibleListenerView, partnerWeighting).score(target);
      });
    });
      console.log(utility)
    // putting more weight on partner's perspective is costly
    factor(utility - ownWeighting * params.perspectiveCost);
    return {weighting: ownWeighting, perspectiveCost: params.perspectiveCost,
            alpha: params.alpha, uttCost: argv.uttCost};
  });
}

// meta-cognitive resource-rational speaker selects optimal mixture
// weight, marginalizing over uncertainty about listener's weight
var RR_listener = function(utt, baseContext) {
  return Infer({method: 'enumerate'}, function() {
    var ownWeighting = sample(possibleWeightings);

    // Marginalize over partner's mixture weight and possible hidden objects
    var utility = expectation(possibleObjects, function(hiddenObj) {
      return expectation(possibleWeightings, function(partnerWeighting) {
        var context = baseContext.concat(hiddenObj + ' private');
          var realSpeakerView = getSpeakerView(context);
	  var worstCaseTarget = last(realSpeakerView)
        var likelyUtt = MAP(S1(worstCaseTarget, realSpeakerView, partnerWeighting))['val'];
        return L1(likelyUtt, context, ownWeighting).score(worstCaseTarget);
      });
    });

    // putting more weight on partner's perspective is costly
    factor(utility - ownWeighting * params.perspectiveCost);
    return {weighting: ownWeighting, perspectiveCost: params.perspectiveCost,
            alpha: params.alpha, uttCost: argv.uttCost};
  });
};

var target = contexts[0]['target']
var speakerContext = contexts[0]['neutral'];
//console.log(JSON.stringify(S1(target, speakerContext.concat(target), 0)))
//console.log(JSON.stringify(RR_speaker(target, speakerContext.concat(target))))
console.log(JSON.stringify(RR_listener(target, speakerContext.concat(target))))
// console.log('resource-rational weight for speaker');
// csv.writeJoint(RR_speaker('texture_color_shape', speakerContext), './output/RRspeakerOutput' + argv.chainNum + '.csv');
// console.log(MAP(RR_speaker('texture_color_shape', speakerContext)));

// console.log('resource-rational weight for listener');
// csv.writeJoint(RR_listener('texture_color_shape', speakerContext), './output/RRlistenerOutput' + argv.chainNum + '.csv');
// console.log(MAP(RR_listener('texture_color_shape', speakerContext)));
