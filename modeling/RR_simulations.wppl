// webppl RR_simulations.wppl --require ./refModule
var context = {
    target: ["two small green square"],
    neutral: ["two small green circle", "one small green star"],
    competitor: ["two small green square", "one small blue triangle"],
    alternative: ["two small green square", "one small green pentagon"],
    private: ["one small green star"]
}

// property categories
var categories = {
  shapes: ["circle", "square", "triangle", "pentagon", "star"],
  colours: ["green", "pink", "black", "blue"],
  sizes: ["small", "big"],
  numbers: ["two", "one"]
};

// subset of possible utterances
var possibleUtterances = Categorical({
  vs: [
    // references to the target
    "green",
    "square",
    "small",
    "two small green square",
    "small green square",
    "green square",
    "two small",
    "two green",
    "two square",
    "small green",
    "small square",

    // references to the competitor, alternative and neutral
    "circle",
    "star",
    "two small green circle",
    "blue square",
    "two small blue square",
    "pentagon",
    "two small green pentagon",

    // references using only
    "small only",
    "green only",
    "square only",
    "circle only",
    "two small green square only",
  ],
});

var possibleScenes = Categorical({
  vs: map(function (v) {
    return v["target"];
  }, _.values(context)),
});

// these are the possible mixture weights for perspective-taking
// where 0 is purely egocentric and 1 is purely partner's perspective
var possibleWeightings = Categorical({
  vs: _.range(0, 1, 0.1),
});

// alpha: soft-max temperature
// <feature>Cost: cost associated with producing this feature
// perspectiveCost: cost associated with perspective-taking
var params = {
  alpha: 3,
  costWeight: 0.02,
  perspectiveCost: 0,
};

var meaning = function (utt, scene) {
  var descriptors = utt.split(" ");
  
  // without "only", we check whether any element matches all the descriptors
  if (!_.includes(descriptors, "only")) {
    return any(function(obj) {
      return all(function(descriptor) {
        return _.includes(obj.split(" "), descriptor);
      }, descriptors);
    }, scene);
  } 
  
  // with "only", we check whether for every category of descriptors, 
  // there is no other object that has a different value for that category
  return all(function(descriptor) {
    // Find which category (if any) the descriptor belongs to
    var category = find(function(key) {
      return _.includes(categories[key], descriptor);
    }, _.keys(categories));
    
    // Get unique values from this category 
    var uniqueValues = reduce(function(obj, values) {
      var value = _.intersection(obj.split(" "), categories[category])[0];
      return _.includes(values, value) ? values : values.concat(value);
    }, [], scene);
    
    // For 'only', check if there is exactly one value in the category
    return uniqueValues.length === 1 && uniqueValues[0] === descriptor;
  }, _.without(descriptors, "only"));
};

var getTrueUtterances = function(context) {
  // Get all objects from the context (excluding private)
  var visibleObjects = _.flatten(_.values(context, 'private'));
  
  // Filter utterances that are true for at least one object
  var trueUtts = filter(function(utt) {
    return any(function(obj) {
      return meaning(utt, obj);
    }, visibleObjects);
  }, possibleUtterances.support());
  
  return Categorical({ vs: trueUtts });
};

// cost of producing utterance is sum of costs of the component words
var uttCost = function (utt) {
  return params.costWeight * utt.split(" ").length;
};

// derives the speaker's perspective from the listener's visible context
var getSpeakerView = function (listenerContext) {
  return _.omit(listenerContext, 'private');
};

// L0 interprets utterance literally using fixed mixture of perspectives
var L0 = cache(function (utt, context, weighting) {
  return Infer({ method: "enumerate" }, function () {
    var partnerContext = flip(weighting) ? getSpeakerView(context) : context;
    var scene = uniformDraw(_.values(partnerContext));
    factor(meaning(utt, scene) ? Math.log(1) : Math.log(0.01));
    return scene;
  });
}, 1000);

// S1 selects utterance using fixed mixture of perspectives
// (given belief about L0's mixture)
var S1 = cache(function (target, context, ownWeighting) {
  return Infer({ method: "enumerate" }, function () {
    var utt = sample(getTrueUtterances(context));
    var egocentricUtility =
      L0(utt, context, 0).score(target) - uttCost(utt, params);
    var combinedUtility = expectation(
      possibleWeightings,
      function (partnerWeighting) {
        var asymmetricUtility = expectation(possibleScenes, function (obj) {
          var possibleListenerView = context.concat(obj + " private");
          return (
            L0(utt, possibleListenerView, partnerWeighting).score(target) -
            uttCost(utt, params)
          );
        });
        return (
          ownWeighting * asymmetricUtility +
          (1 - ownWeighting) * egocentricUtility
        );
      }
    );
    factor(params.alpha * combinedUtility);
    return utt;
  });
});

// L1 selects objects given belief about S1's mixture
var L1 = function (utt, context, ownWeighting) {
  return Infer({ method: "enumerate" }, function () {
    var perspective = flip(ownWeighting) ? "other" : "own";
    var partnerContext =
      perspective == "own" ? context : getSpeakerView(context);
    var partnerWeight = perspective == "own" ? 0 : sample(possibleWeightings);

    var object = uniformDraw(partnerContext);
    observe(S1(object, partnerContext, partnerWeight), utt);
    return object;
  });
};

// meta-cognitive resource-rational speaker selects optimal mixture
// weight, marginalizing over uncertainty about listener's weight
var RR_speaker = function (target, context) {
  return Infer({ method: "enumerate" }, function () {
    var ownWeighting = sample(possibleWeightings);

    // Imagine how speaker with this weight would behave
    var likelyUtt = MAP(S1(target, context, ownWeighting))["val"];
    console.log(likelyUtt);
    // Imagine expected utility of that behavior, marginalizing over
    // partner's mixture weight and possible objects in partner's view
    var utility = expectation(possibleScenes, function (obj) {
      return expectation(possibleWeightings, function (partnerWeighting) {
        var possibleListenerView = context.concat(obj + " private");
        return L0(likelyUtt, possibleListenerView, partnerWeighting).score(
          target
        );
      });
    });
    console.log(utility);
    // putting more weight on partner's perspective is costly
    factor(utility - ownWeighting * params.perspectiveCost);
    return {
      weighting: ownWeighting,
      perspectiveCost: params.perspectiveCost,
      alpha: params.alpha,
      //uttCost: argv.uttCost,
    };
  });
};

// meta-cognitive resource-rational speaker selects optimal mixture
// weight, marginalizing over uncertainty about listener's weight
var RR_listener = function (utt, baseContext) {
  return Infer({ method: "enumerate" }, function () {
    var ownWeighting = sample(possibleWeightings);

    // Marginalize over partner's mixture weight and possible hidden objects
    var utility = expectation(possibleScenes, function (hiddenObj) {
      return expectation(possibleWeightings, function (partnerWeighting) {
        var context = baseContext.concat(hiddenObj + " private");
        var realSpeakerView = getSpeakerView(context);
        var worstCaseTarget = last(realSpeakerView);
        var likelyUtt = MAP(
          S1(worstCaseTarget, realSpeakerView, partnerWeighting)
        )["val"];
        return L1(likelyUtt, context, ownWeighting).score(worstCaseTarget);
      });
    });

    // putting more weight on partner's perspective is costly
    factor(utility - ownWeighting * params.perspectiveCost);
    return {
      weighting: ownWeighting,
      perspectiveCost: params.perspectiveCost,
      alpha: params.alpha,
    };
  });
};

// Helper function to run a test and show pass/fail status
var runTest = function(name, utterance, scene, expected) {
  var result = meaning(utterance, scene);
  var passed = result === expected;
  var status = passed ? "✓ PASS" : "✗ FAIL";
  console.log(name + ": " + status + " (got " + result + ", expected " + expected + ")");
};

// Basic property tests
console.log("\nBasic property tests:");
runTest("1. Basic circle match", "circle", ["two small green circle"], true);
runTest("2. No circle match", "circle", ["two small green square"], false);
runTest("3. Color match", "green", ["two small green circle"], true);
runTest("4. Multiple properties", "small green", ["two small green square"], true);

// Multiple objects in scene
console.log("\nMultiple objects tests:");
runTest("5. Green in all objects", "green", ["two small green circle", "one small green star"], true);
runTest("6. No blue objects", "blue", ["two small green circle", "one small green star"], false);
runTest("7. Small in all objects", "small", ["two small green circle", "one small green star"], true);

// 'only' tests
console.log("\n'only' tests:");
runTest("8. Only circles (single object)", "circle only", ["two small green circle"], true);
runTest("9. Only circles (multiple objects)", "circle only", ["two small green circle", "one small green star"], false);
runTest("10. Only green", "green only", ["two small green circle", "one small green star"], true);
runTest("11. Only small", "small only", ["two small green circle", "one small green star"], true);
runTest("12. Only star", "star only", ["two small green circle", "one small green star"], false);


// Multiple descriptors with 'only'
console.log("\nMultiple descriptors with 'only':");
runTest("17. Only small and green", "small green only", ["two small green circle", "one small green star"], true);
runTest("18. Only small and green (different colors)", "small green only", ["two small green circle", "one small blue star"], false);
runTest("19. Only small and green (different sizes)", "small green only", ["two small green circle", "one big green star"], false);

// Helper function to run L0 tests
var runL0Test = function(name, utterance, context, weighting, expectedTarget, expectedProbability) {
  var result = L0(utterance, context, weighting);
  var targetProbability = Math.exp(result.score(expectedTarget));
  var passed = Math.abs(targetProbability - expectedProbability) < 0.01;
  var status = passed ? "✓ PASS" : "✗ FAIL";
  console.log(name + ": " + status + 
    " (got " + targetProbability.toFixed(3) + 
    ", expected " + expectedProbability.toFixed(3) + ")");
};

// L0 Tests
console.log("\nL0 Tests:");
console.log(context);

// Test 1: Basic egocentric interpretation (weighting = 0)
runL0Test(
  "1. Basic egocentric interpretation",
  "green",
  context,
  0,
  context.target,
  0.2  // Updated probability based on actual context size
);

// Test 2: Basic partner perspective interpretation (weighting = 1)
runL0Test(
  "2. Basic partner perspective interpretation",
  "green",
  context,
  1,
  context.target,
  0.25  // Updated probability based on actual context size
);

// Test 3: Mixed perspective (weighting = 0.5)
runL0Test(
  "3. Mixed perspective interpretation",
  "green",
  context,
  0.5,
  context.target,
  0.225 // Updated probability based on actual context size
);

// Test 4: Specific utterance with multiple properties
runL0Test(
  "4. Specific utterance with multiple properties",
  "two small green square",
  context,
  0,
  context.target,
  0.333
);

// Test 5: 'only' utterance
runL0Test(
  "5. 'only' utterance interpretation",
  "square only",
  context,
  0,
  context.target,
  0.96  // Updated probability based on actual context size
);

// Test 6: Non-matching utterance
runL0Test(
  "6. Non-matching utterance",
  "blue",
  context,
  0,
  context.target,
  0.0
);
